# train_compression.py

# VGG ê¸°ë°˜ Perceptual Loss + MSE Loss ì¶”ê°€ X
""" import torch
import torch.optim as optim
import torch.nn as nn
from ast_compression_model import ASTCompressionRestoration
from compression_dataloader import get_compression_dataloader
import time  # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ëª¨ë“ˆ

# âœ… 1. í™˜ê²½ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… ì‹¤í–‰ í™˜ê²½: {device}")

# âœ… 2. ë°ì´í„°ì…‹ ë¡œë“œ
csv_path = "C:/Users/IIPL02/Desktop/NEW/data/KADID10K/kadid10k.csv"
img_dir = "C:/Users/IIPL02/Desktop/NEW/data/KADID10K/images"

print("ğŸ”¹ ë°ì´í„° ë¡œë“œ ì¤‘...")
dataloader = get_compression_dataloader(csv_path, img_dir, batch_size=4)
print(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ! ì´ {len(dataloader.dataset)}ê°œì˜ JPEG/JPEG2000 ì´ë¯¸ì§€ í¬í•¨.")

# âœ… 3. ëª¨ë¸ ì´ˆê¸°í™”
print("ğŸ”¹ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
model = ASTCompressionRestoration().to(device)
optimizer = optim.Adam(model.parameters(), lr=1e-4)
criterion = nn.MSELoss()
print("âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ.")

# âœ… 4. í•™ìŠµ ë£¨í”„
num_epochs = 50
print(f"ğŸ”¹ {num_epochs} Epoch ë™ì•ˆ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")

start_time = time.time()  # ì „ì²´ í•™ìŠµ ì‹œê°„ ì¸¡ì • ì‹œì‘

for epoch in range(num_epochs):
    epoch_start = time.time()  # ê° epoch ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
    model.train()
    total_loss = 0

    print(f"\nğŸš€ Epoch [{epoch+1}/{num_epochs}] ì‹œì‘...")

    for batch_idx, (img, ref) in enumerate(dataloader):
        batch_start = time.time()  # ë°°ì¹˜ë³„ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •

        img, ref = img.to(device), ref.to(device)

        optimizer.zero_grad()
        restored = model(img)
        loss = criterion(restored, ref)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

        batch_time = time.time() - batch_start  # ë°°ì¹˜ë³„ ì†Œìš” ì‹œê°„ ì¸¡ì •
        print(f"   ğŸŸ¢ Batch {batch_idx+1}/{len(dataloader)} ì™„ë£Œ (Loss: {loss.item():.6f}, Time: {batch_time:.3f}s)")

    epoch_time = time.time() - epoch_start  # Epoch ì†Œìš” ì‹œê°„ ì¸¡ì •
    avg_loss = total_loss / len(dataloader)

    print(f"âœ… Epoch [{epoch+1}/{num_epochs}] ì™„ë£Œ | í‰ê·  Loss: {avg_loss:.6f} | Epoch Time: {epoch_time:.2f}s")

total_time = time.time() - start_time  # ì „ì²´ í•™ìŠµ ì‹œê°„ ì¸¡ì •
print(f"\nâœ… ëª¨ë“  Epoch í•™ìŠµ ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}s")

# âœ… 5. ëª¨ë¸ ì €ì¥
model_save_path = "compression_restoration.pth"
torch.save(model.state_dict(), model_save_path)
print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}")
 """

# VGG ê¸°ë°˜ Perceptual Loss + MSE Loss ì¶”ê°€ O
# train_compression.py
# train_compression.py
import torch
import torch.nn as nn
import torch.optim as optim
from ast_compression_model import ASTCompressionRestoration
from compression_dataloader import get_compression_dataloader
from torchvision.models import vgg16
import time

# âœ… VGG ê¸°ë°˜ Perceptual Loss ì •ì˜
class VGGPerceptualLoss(nn.Module):
    def __init__(self):
        super(VGGPerceptualLoss, self).__init__()
        vgg = vgg16(pretrained=True).features[:16]  # conv3_3ê¹Œì§€ ì‚¬ìš©
        for param in vgg.parameters():
            param.requires_grad = False
        self.vgg = vgg.eval()
        self.criterion = nn.L1Loss()

    def forward(self, x, y):
        x_vgg = self.vgg(x)
        y_vgg = self.vgg(y)
        return self.criterion(x_vgg, y_vgg)

# âœ… 1. í™˜ê²½ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… ì‹¤í–‰ í™˜ê²½: {device}")

# âœ… 2. ë°ì´í„°ì…‹ ë¡œë“œ
csv_path = "C:/Users/IIPL02/Desktop/NEW/data/KADID10K/kadid10k.csv"
img_dir = "C:/Users/IIPL02/Desktop/NEW/data/KADID10K/images"

print("ğŸ”¹ ë°ì´í„° ë¡œë“œ ì¤‘...")
dataloader = get_compression_dataloader(csv_path, img_dir, batch_size=4)
print(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ! ì´ {len(dataloader.dataset)}ê°œì˜ JPEG/JPEG2000 ì´ë¯¸ì§€ í¬í•¨.")

# âœ… 3. ëª¨ë¸ ë° ì†ì‹¤ í•¨ìˆ˜ ì´ˆê¸°í™”
print("ğŸ”¹ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
model = ASTCompressionRestoration().to(device)
optimizer = optim.Adam(model.parameters(), lr=1e-4)
mse_loss = nn.MSELoss()
perc_loss = VGGPerceptualLoss().to(device)
print("âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ.")

# âœ… 4. í•™ìŠµ ë£¨í”„
num_epochs = 1
print(f"ğŸ”¹ {num_epochs} Epoch ë™ì•ˆ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")

start_time = time.time()

for epoch in range(num_epochs):
    epoch_start = time.time()
    model.train()
    total_loss = 0

    print(f"\nğŸš€ Epoch [{epoch+1}/{num_epochs}] ì‹œì‘...")

    for batch_idx, (img, ref, distortion_class) in enumerate(dataloader):
        batch_start = time.time()

        img = img.to(device)
        ref = ref.to(device)
        distortion_class = distortion_class.to(device)  # ê·¸ëŒ€ë¡œ ìœ ì§€ (ë°°ì¹˜ ì „ì²´)

        optimizer.zero_grad()

        # âœ… class_idë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ëª¨ë¸ì— ë„˜ê¹€
        restored = model(img, class_id=distortion_class)

        # âœ… ì†ì‹¤ ê³„ì‚°
        loss_mse = mse_loss(restored, ref)
        loss_perc = perc_loss(restored, ref)
        loss = loss_mse + 0.1 * loss_perc

        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        batch_time = time.time() - batch_start

        print(f"   ğŸŸ¢ Batch {batch_idx+1}/{len(dataloader)} ì™„ë£Œ (Loss: {loss.item():.6f}, Time: {batch_time:.3f}s)")


    epoch_time = time.time() - epoch_start
    avg_loss = total_loss / len(dataloader)
    print(f"âœ… Epoch [{epoch+1}/{num_epochs}] ì™„ë£Œ | í‰ê·  Loss: {avg_loss:.6f} | Epoch Time: {epoch_time:.2f}s")

total_time = time.time() - start_time
print(f"\nâœ… ëª¨ë“  Epoch í•™ìŠµ ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}s")

# âœ… 5. ëª¨ë¸ ì €ì¥
model_save_path = "compression_restoration_with_perceptual.pth"
torch.save(model.state_dict(), model_save_path)
print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}")
